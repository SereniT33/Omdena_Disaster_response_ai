{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTKAeSjRaBiKHntp8O59YF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SereniT33/Omdena_Disaster_response_ai/blob/main/Useful_codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Useful code snippets"
      ],
      "metadata": {
        "id": "rva3JHjDh_NK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Dataset"
      ],
      "metadata": {
        "id": "uek8AozNheWl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNzu4scThWdb"
      },
      "outputs": [],
      "source": [
        "DATADIR= \"...file path...\"\n",
        "CATEGORIES=[\"Damaged\",\"Undamaged\"]\n",
        "#Iterate through the two categories\n",
        "for category in CATEGORIES:\n",
        "    path= os.path.join(DATADIR,category)\n",
        "    for img in os.listdir(path):\n",
        "        img_array= cv2.imread(os.path.join(path,img))\n",
        "        plt.imshow(img_array)\n",
        "        plt.show()\n",
        "        break\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read or resize the image"
      ],
      "metadata": {
        "id": "hLb4wxTshimm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code snippet 1\n",
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('example.jpg')\n",
        "\n",
        "# Resize the image to a specific width and height\n",
        "width = 300\n",
        "height = 200\n",
        "resized_image = cv2.resize(image, (width, height))"
      ],
      "metadata": {
        "id": "BMg1IgzjhmB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resizing all images to one size\n",
        "training_data=[]\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:\n",
        "        path= os.path.join(DATADIR,category)\n",
        "        class_num = CATEGORIES.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array= cv2.imread(os.path.join(path,img))\n",
        "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
        "                training_data.append([new_array,class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "create_training_data()\n",
        "#Checking the new image size\n",
        "new_array.shape"
      ],
      "metadata": {
        "id": "zCfxsmG3hr0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model (CNN)"
      ],
      "metadata": {
        "id": "7xqvo9pchvTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating features and labels for the images in our dataset\n",
        "X_calamity=[]#features\n",
        "y_calamity=[]#labels\n",
        "for features, label in training_data:\n",
        "    X_calamity.append(features)\n",
        "    y_calamity.append(label)\n",
        "#Converting image input to array\n",
        "X_calamity= np.array(X_calamity).reshape(-3,IMG_SIZE,IMG_SIZE,3)\n",
        "#Normalising the image input array\n",
        "X_calamity=X_calamity/255.0"
      ],
      "metadata": {
        "id": "tUZM7x1NhyaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formulate the model"
      ],
      "metadata": {
        "id": "tAXv6zYnh3Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#Second Convolutional layer\n",
        "model.add(Conv2D(kernel_size=3, strides=1, filters=64, padding='same', activation='relu', name='layer_conv2'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#Third Convolutional layer\n",
        "model.add(Conv2D(kernel_size=3, strides=1, filters=128, padding='same', activation='relu', name='layer_conv3'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#Drop-out layer\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
        "#Fourth Convolutional layer\n",
        "model.add(Conv2D(kernel_size=3, strides=1, filters=64, padding='same', activation='relu', name='layer_conv4'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#Fifth Convolutional layer\n",
        "model.add(Conv2D(kernel_size=3, strides=1, filters=32, padding='same', activation='relu', name='layer_conv5'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#Sixth Convolutional layer\n",
        "model.add(Conv2D(kernel_size=3, strides=1, filters=16, padding='same', activation='relu', name='layer_conv6'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32)) #Fully Connected Layer\n",
        "model.add(Activation(\"relu\"))\n",
        "#Output layer\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "             optimizer=\"adam\", metrics=['accuracy'])\n",
        "#Displaying model summary statistics\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xsObCATYh0JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "VFxqx9s3iJTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_calamity, y_calamity, batch_size=65, epochs=20, validation_split=0.1)"
      ],
      "metadata": {
        "id": "tJnZfpfwiKWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the results"
      ],
      "metadata": {
        "id": "RhQk-6H9iNrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper Function to plot images\n",
        "def plot_images(images, cls_true, cls_pred=None):\n",
        "    assert len(images) == len(cls_true) == 9\n",
        "\n",
        "    # Create figure with 3x3 sub-plots\n",
        "    fig, axes = plt.subplots(3, 3)\n",
        "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "        # Plot image\n",
        "        ax.imshow(images[i].reshape(image_shape), cmap='binary')\n",
        "#Show true and predicted classes\n",
        "        if cls_pred is None:\n",
        "            xlabel = \"True: {0}\".format(cls_true[i])\n",
        "        else:\n",
        "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
        "#Show the classes as the label on the x-axis\n",
        "        ax.set_xlabel(xlabel)\n",
        "\n",
        "        # Remove ticks from the plot\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CcPOCzT_iQGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Plot images and labels"
      ],
      "metadata": {
        "id": "ZKRwM_seiSAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining parameters\n",
        "images = X_calamity[0:9]\n",
        "cls_true =y_calamity[0:9]\n",
        "y_pred = model.predict(x=images)\n",
        "cls_pred = np.argmax(y_pred, axis=1)\n",
        "#Plotting images\n",
        "plot_images(images=images, cls_true=cls_true, cls_pred=cls_pred)"
      ],
      "metadata": {
        "id": "YUorvNYgiV_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper Function to plot incorrect images\n",
        "def plot_example_errors(cls_pred):\n",
        "#cls_pred is an array of the predicted class-number for all images in the test-set\n",
        "# Boolean array whether the predicted class is incorrect.\n",
        "    incorrect = (cls_pred != y_calamity)\n",
        "# Get the images from the test-set that have been incorrectly classified\n",
        "    images = X_calamity[incorrect]\n",
        "\n",
        "    #Get the predicted classes for those images\n",
        "    cls_pred = cls_pred[incorrect]\n",
        "#Get the true classes for those images\n",
        "    cls_true = y_calamity[incorrect]\n",
        "\n",
        "    #Plot the first 9 images\n",
        "    plot_images(images=images[0:9], cls_true=cls_true[0:9], cls_pred=cls_pred[0:9])"
      ],
      "metadata": {
        "id": "4rndLIkaiXjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining parameters\n",
        "y_pred = model.predict(x=X_calamity)\n",
        "cls_pred = np.argmax(y_pred, axis=1)\n",
        "#Plotting images\n",
        "plot_example_errors(cls_pred)"
      ],
      "metadata": {
        "id": "MmTTfIjMiYxt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}